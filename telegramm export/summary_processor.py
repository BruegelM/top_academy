#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–æ–≤ –∏–∑ —Ç–µ–ª–µ–≥—Ä–∞–º –∫–∞–Ω–∞–ª–æ–≤ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º —Å–∞–º–º–∞—Ä–∏
–í–º–µ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ—Å—Ç–æ–≤ —Å–æ–∑–¥–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–∞–º–º–∞—Ä–∏
"""

import asyncio
import argparse
import sys
import logging
import re
from datetime import datetime
from database import DatabaseManager
from ai_analyzers import ZelibobaAnalyzer, ElizaAnalyzer
from models_optimized import MessageProcessor
from config import AISettings

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('summary_processor.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PostSummaryProcessor:
    def __init__(self):
        self.db = DatabaseManager()
        if not self.db.connect():
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            sys.exit(1)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –∏–∑ –Ω–æ–≤—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        self.zeliboba_analyzer = None
        self.eliza_analyzer = None
        
        if AISettings.ZELIBOBA['api_token']:
            self.zeliboba_analyzer = ZelibobaAnalyzer(
                AISettings.ZELIBOBA['api_token'],
                AISettings.ZELIBOBA['base_url'],
                AISettings.ZELIBOBA['model'],
                AISettings.ZELIBOBA['temperature']
            )
        
        if AISettings.ELIZA['api_token']:
            self.eliza_analyzer = ElizaAnalyzer(
                AISettings.ELIZA['api_token'],
                AISettings.ELIZA['base_url'],
                AISettings.ELIZA['model'],
                AISettings.ELIZA['temperature']
            )
        
        if not self.zeliboba_analyzer and not self.eliza_analyzer:
            logger.error("–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã API —Ç–æ–∫–µ–Ω—ã –¥–ª—è Zeliboba –∏–ª–∏ Eliza")
            sys.exit(1)
            
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–∞–º–º–∞—Ä–∏ (Zeliboba: {AISettings.ZELIBOBA['model'] if self.zeliboba_analyzer else '–Ω–µ—Ç'}, Eliza: {AISettings.ELIZA['model'] if self.eliza_analyzer else '–Ω–µ—Ç'})")

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if hasattr(self, 'db'):
            self.db.disconnect()
        if hasattr(self, 'eliza_analyzer') and self.eliza_analyzer:
            await self.eliza_analyzer.close()
        if hasattr(self, 'zeliboba_analyzer') and self.zeliboba_analyzer:
            await self.zeliboba_analyzer.close()

    def __del__(self):
        if hasattr(self, 'db'):
            self.db.disconnect()

    def extract_summary_parts(self, analysis_text: str) -> tuple:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å, —Å–∞–º–º–∞—Ä–∏ –∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑ –æ—Ç–≤–µ—Ç–∞ GPT
        
        Args:
            analysis_text: —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT
            
        Returns:
            tuple: (main_idea, summary, full_analysis)
        """
        try:
            # –ò—â–µ–º –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å
            main_idea_match = re.search(
                r'(?:–ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï|–ì–õ–ê–í–ù–ê–Ø –ú–´–°–õ–¨):\s*(.+?)(?:\n\n|$)',
                analysis_text,
                re.DOTALL | re.IGNORECASE
            )
            main_idea = main_idea_match.group(1).strip() if main_idea_match else ""
            
            # –ò—â–µ–º —Å–∞–º–º–∞—Ä–∏ (–ø–µ—Ä–≤—ã–µ 1000 —Å–ª–æ–≤)
            summary = analysis_text[:1000] + "..." if len(analysis_text) > 1000 else analysis_text
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
            if not main_idea:
                sentences = analysis_text.split('.')
                main_idea = sentences[0].strip() + '.' if sentences else analysis_text[:200] + "..."
            
            # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            full_analysis = analysis_text
            
            return main_idea, summary, full_analysis
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–∞—Å—Ç–µ–π —Å–∞–º–º–∞—Ä–∏: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            return analysis_text[:200] + "..." if len(analysis_text) > 200 else analysis_text, analysis_text
    
    async def process_posts_to_summaries(self, limit=None):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å—Ç—ã –∏–∑ —Ç–∞–±–ª–∏—Ü—ã posts –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–∞–º–º–∞—Ä–∏"""
        logger.info("–ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç—ã, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —Å–∞–º–º–∞—Ä–∏
            query = """
                SELECT p.* FROM posts p
                LEFT JOIN post_summaries ps ON p.channel_id = ps.channel_id 
                    AND p.telegram_message_id = ps.telegram_message_id
                WHERE ps.id IS NULL
                AND p.content IS NOT NULL
                AND p.content != ''
                ORDER BY p.date_published DESC
            """
            
            if limit:
                query += f" LIMIT {limit}"
            
            self.db.cursor.execute(query)
            posts = self.db.cursor.fetchall()
            
            if not posts:
                logger.info("–í—Å–µ –ø–æ—Å—Ç—ã —É–∂–µ –∏–º–µ—é—Ç —Å–∞–º–º–∞—Ä–∏")
                return
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(posts)} –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏")
            
            success_count = 0
            error_count = 0
            
            for i, post in enumerate(posts, 1):
                try:
                    logger.info(f"–°–æ–∑–¥–∞–µ–º —Å–∞–º–º–∞—Ä–∏ –¥–ª—è –ø–æ—Å—Ç–∞ {i}/{len(posts)} (ID: {post['id']})")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    if len(post['content']) < 50:
                        logger.warning(f"–ü–æ—Å—Ç {post['id']} —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å–∞–º–º–∞—Ä–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–∞–º–º–∞—Ä–∏ —á–µ—Ä–µ–∑ Eliza –∏–ª–∏ Zeliboba
                    summary_result = None
                    if self.eliza_analyzer:
                        summary_result = await self.eliza_analyzer.analyze_content(
                            content=post['content'],
                            prompt="–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏–π"
                        )
                    
                    # –ï—Å–ª–∏ Eliza –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–±—É–µ–º Zeliboba
                    if (not summary_result or summary_result.get("status") != "success") and self.zeliboba_analyzer:
                        summary_result = await self.zeliboba_analyzer.create_summary(post['content'])
                    
                    if summary_result and summary_result.get("status") == "success":
                        analysis_text = summary_result.get("analysis_text", "")
                        
                        if analysis_text:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å –∏ —Å–∞–º–º–∞—Ä–∏
                            main_idea, summary = self.extract_summary_parts(analysis_text)
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–º–º–∞—Ä–∏ –∏ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                            summary_id = self.db.save_post_summary(
                                channel_id=post['channel_id'],
                                telegram_message_id=post['telegram_message_id'],
                                sender_name=post['sender_name'],
                                sender_id=post['sender_id'],
                                summary=summary,
                                main_idea=main_idea,
                                date_published=post['date_published'],
                                views_count=post['views_count'],
                                forwards_count=post['forwards_count'],
                                replies_count=post['replies_count'],
                                analysis=analysis_text  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                            )
                            
                            if summary_id:
                                logger.info(f"‚úÖ –°–∞–º–º–∞—Ä–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–æ –¥–ª—è –ø–æ—Å—Ç–∞ {post['id']} (Summary ID: {summary_id})")
                                success_count += 1
                                
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–∑–¥–∞–Ω–Ω–æ–º —Å–∞–º–º–∞—Ä–∏
                                logger.debug(f"–ì–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å: {main_idea[:100]}...")
                                logger.debug(f"–°–∞–º–º–∞—Ä–∏: {summary[:200]}...")
                            else:
                                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∞–º–º–∞—Ä–∏ –¥–ª—è –ø–æ—Å—Ç–∞ {post['id']}")
                                error_count += 1
                        else:
                            logger.error(f"‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GPT –¥–ª—è –ø–æ—Å—Ç–∞ {post['id']}")
                            error_count += 1
                    else:
                        error_message = summary_result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if summary_result else "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏ –¥–ª—è –ø–æ—Å—Ç–∞ {post['id']}: {error_message}")
                        error_count += 1
                    
                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                    await asyncio.sleep(1.0)
                    
                except Exception as e:
                    logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å—Ç–∞ {post['id']}: {e}")
                    error_count += 1
            
            logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£—Å–ø–µ—à–Ω–æ: {success_count}, –û—à–∏–±–æ–∫: {error_count}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
    
    async def get_processing_statistics(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ—Å—Ç–∞–º
            self.db.cursor.execute("SELECT COUNT(*) as total_posts FROM posts WHERE content IS NOT NULL")
            posts_stats = self.db.cursor.fetchone()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∞–º–º–∞—Ä–∏
            self.db.cursor.execute("SELECT COUNT(*) as total_summaries FROM post_summaries")
            summaries_stats = self.db.cursor.fetchone()
            
            # –ü–æ—Å—Ç—ã –±–µ–∑ —Å–∞–º–º–∞—Ä–∏
            self.db.cursor.execute("""
                SELECT COUNT(*) as posts_without_summaries FROM posts p
                LEFT JOIN post_summaries ps ON p.channel_id = ps.channel_id 
                    AND p.telegram_message_id = ps.telegram_message_id
                WHERE ps.id IS NULL AND p.content IS NOT NULL AND p.content != ''
            """)
            pending_stats = self.db.cursor.fetchone()
            
            logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∞–º–º–∞—Ä–∏:")
            logger.info(f"   –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º: {posts_stats['total_posts']}")
            logger.info(f"   –°–æ–∑–¥–∞–Ω–æ —Å–∞–º–º–∞—Ä–∏: {summaries_stats['total_summaries']}")
            logger.info(f"   –û–∂–∏–¥–∞—é—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pending_stats['posts_without_summaries']}")
            
            if posts_stats['total_posts'] > 0:
                completion_rate = (summaries_stats['total_summaries'] / posts_stats['total_posts']) * 100
                logger.info(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {completion_rate:.1f}%")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    async def test_summary_creation(self, test_text: str = None):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏"""
        if not test_text:
            test_text = """
            –ù–æ–≤–∞—è –≥–æ—Å—Ç–∏–Ω–∏—Ü–∞ Marriott –æ—Ç–∫—Ä—ã–ª–∞—Å—å –≤ —Ü–µ–Ω—Ç—Ä–µ –ú–æ—Å–∫–≤—ã. –û—Ç–µ–ª—å –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç 200 –Ω–æ–º–µ—Ä–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, 
            –≤–∫–ª—é—á–∞—è –ª—é–∫—Å—ã —Å –≤–∏–¥–æ–º –Ω–∞ –ö—Ä–µ–º–ª—å. –í –æ—Ç–µ–ª–µ —Ä–∞–±–æ—Ç–∞—é—Ç —Ç—Ä–∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞, —Å–ø–∞-—Ü–µ–Ω—Ç—Ä –∏ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü-–∑–∞–ª—ã. 
            –£–ø—Ä–∞–≤–ª—è—é—â–∏–π –æ—Ç–µ–ª–µ–º –æ—Ç–º–µ—Ç–∏–ª, —á—Ç–æ –æ–Ω–∏ –æ–∂–∏–¥–∞—é—Ç –≤—ã—Å–æ–∫—É—é –∑–∞–≥—Ä—É–∑–∫—É –±–ª–∞–≥–æ–¥–∞—Ä—è —É–¥–∞—á–Ω–æ–º—É —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é. 
            –°—Ç–æ–∏–º–æ—Å—Ç—å –Ω–æ–º–µ—Ä–æ–≤ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ—Ç 15 000 —Ä—É–±–ª–µ–π –∑–∞ –Ω–æ—á—å. –û—Ç–µ–ª—å —É–∂–µ –ø—Ä–∏–Ω—è–ª –ø–µ—Ä–≤—ã—Ö –≥–æ—Å—Ç–µ–π –∏ –ø–æ–ª—É—á–∏–ª 
            –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –æ –∫–∞—á–µ—Å—Ç–≤–µ —Å–µ—Ä–≤–∏—Å–∞.
            """
        
        logger.info("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏...")
        
        try:
            summary_result = None
            if self.eliza_analyzer:
                summary_result = await self.eliza_analyzer.analyze_content(
                    content=test_text,
                    prompt="–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –Ø–Ω–¥–µ–∫—Å –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏–π"
                )
            
            if (not summary_result or summary_result.get("status") != "success") and self.zeliboba_analyzer:
                summary_result = await self.zeliboba_analyzer.create_summary(test_text)
            
            if summary_result and summary_result.get("status") == "success":
                analysis_text = summary_result.get("analysis_text", "")
                main_idea, summary = self.extract_summary_parts(analysis_text)
                
                logger.info("‚úÖ –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ")
                logger.info(f"–ì–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å: {main_idea}")
                logger.info(f"–°–∞–º–º–∞—Ä–∏: {summary}")
                logger.info(f"–î–ª–∏–Ω–∞ —Å–∞–º–º–∞—Ä–∏: {len(summary.split())} —Å–ª–æ–≤")
                return True
            else:
                error = summary_result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞") if summary_result else "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {error}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            return False

async def main():
    parser = argparse.ArgumentParser(description="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–æ–≤ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º —Å–∞–º–º–∞—Ä–∏")
    parser.add_argument("--process", action="store_true", help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å—Ç—ã –∏ —Å–æ–∑–¥–∞—Ç—å —Å–∞–º–º–∞—Ä–∏")
    parser.add_argument("--stats", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    parser.add_argument("--test", action="store_true", help="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏")
    parser.add_argument("--limit", type=int, help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    args = parser.parse_args()
    
    processor = PostSummaryProcessor()
    
    if args.test:
        success = await processor.test_summary_creation()
        if not success:
            sys.exit(1)
    
    if args.stats:
        await processor.get_processing_statistics()
    
    if args.process:
        await processor.process_posts_to_summaries(args.limit)
    
    if not any([args.process, args.stats, args.test]):
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python summary_processor.py --test                    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∞–º–º–∞—Ä–∏")
        print("  python summary_processor.py --process                 # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –ø–æ—Å—Ç—ã")
        print("  python summary_processor.py --process --limit 10      # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å 10 –ø–æ—Å—Ç–æ–≤")
        print("  python summary_processor.py --stats                   # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É")

if __name__ == "__main__":
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        processor = loop.run_until_complete(main())
        if hasattr(processor, 'close'):
            loop.run_until_complete(processor.close())
    finally:
        loop.close()
