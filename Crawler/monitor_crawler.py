#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–µ–±-–∫—Ä–∞—É–ª–µ—Ä–∞
"""
import os
import time
import json
from pathlib import Path
import sqlite3

def check_crawler_status():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫—Ä–∞—É–ª–µ—Ä–∞"""
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –≤–µ–±-–∫—Ä–∞—É–ª–µ—Ä–∞...")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_dir = Path("travel_yandex_results")
    if results_dir.exists():
        print(f"‚úÖ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–∞: {results_dir}")
        files = list(results_dir.glob("*"))
        if files:
            print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")
            for file in files:
                size = file.stat().st_size
                print(f"   - {file.name}: {size} –±–∞–π—Ç")
        else:
            print("üìÅ –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—É—Å—Ç–∞")
    else:
        print("‚ùå –ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    db_path = Path("crawler_data/crawler.db")
    if db_path.exists():
        print(f"\n‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        try:
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è—Ö
                cursor.execute("SELECT * FROM crawls ORDER BY id DESC LIMIT 5")
                crawls = cursor.fetchall()
                
                if crawls:
                    print("\nüìä –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:")
                    for crawl in crawls:
                        crawl_id, domain, start_time, end_time, total_pages, status, config = crawl
                        print(f"   ID: {crawl_id}, –î–æ–º–µ–Ω: {domain}")
                        print(f"   –°—Ç–∞—Ç—É—Å: {status}, –°—Ç—Ä–∞–Ω–∏—Ü: {total_pages or 'N/A'}")
                        print(f"   –ù–∞—á–∞–ª–æ: {start_time}")
                        print(f"   –ö–æ–Ω–µ—Ü: {end_time or '–í –ø—Ä–æ—Ü–µ—Å—Å–µ'}")
                        print()
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
                        if crawl == crawls[0]:  # –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
                            cursor.execute("""
                                SELECT 
                                    COUNT(*) as total,
                                    COUNT(CASE WHEN status_code = 200 THEN 1 END) as success,
                                    COUNT(CASE WHEN status_code >= 400 THEN 1 END) as errors,
                                    MAX(depth) as max_depth
                                FROM pages WHERE crawl_id = ?
                            """, (crawl_id,))
                            stats = cursor.fetchone()
                            if stats and stats[0] > 0:
                                total, success, errors, max_depth = stats
                                print(f"   üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü:")
                                print(f"      –í—Å–µ–≥–æ: {total}")
                                print(f"      –£—Å–ø–µ—à–Ω–æ: {success}")
                                print(f"      –û—à–∏–±–∫–∏: {errors}")
                                print(f"      –ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞: {max_depth}")
                else:
                    print("\nüìä –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –ë–î: {e}")
    else:
        print("\n‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥ —Ñ–∞–π–ª—ã
    log_files = [
        "crawler_test.log",
        "crawler.log"
    ]
    
    print("\nüìã –õ–æ–≥ —Ñ–∞–π–ª—ã:")
    for log_file in log_files:
        log_path = Path(log_file)
        if log_path.exists():
            size = log_path.stat().st_size
            print(f"   ‚úÖ {log_file}: {size} –±–∞–π—Ç")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
            try:
                with open(log_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        print(f"      –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏:")
                        for line in lines[-3:]:
                            print(f"      {line.strip()}")
            except Exception as e:
                print(f"      –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
        else:
            print(f"   ‚ùå {log_file}: –Ω–µ –Ω–∞–π–¥–µ–Ω")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        check_crawler_status()
        
        print("\n" + "=" * 50)
        print("üîÑ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()